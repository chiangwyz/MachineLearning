# 支持向量机

支持向量机(Support vector machine, SVM)，既可以用于分类，也可以用于回归。

本节介绍如何将线性支持向量机应用于二元分类问题，以间隔(margin)最大化为基准，得到更好的决策边界。


## 概述

本节使用线性支持向量机(Linear support vector machine, LSVM)处理二元分类，线性支持向量机是以间隔最大化为基准，来学习得到尽可能地远离数据的决策边界的算法。虽然该算法的决策边界与逻辑回归一样是线性的，但有时线性支持向量机得到的结果更好。

**线性支持向量机的学习方式是：以间隔最大化为基准，让决策边界尽可能地远离数据**

## 算法说明

线性支持向量机通过最大化间隔来获得更好的用于分类的决策边界，首先需要阐述下间隔的定义，为了方便起见，我们以平面上的二元分类问题为例进行说明，并且假设数据可以完全分类。LSVM通过线性的决策边界平面一分为二，此时，训练数据中最接近决策边界的数据与决策边界之间的距离就成为间隔。

## 示例代码

```python
from sklearn.svm import LinearSVC
from sklearn.datasets import make_blobs
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score


# 数据生成
centers = [(-1, -0.125), (0.5, 0.5)]
X, y = make_blobs(n_samples=50, n_features=2, centers=centers, cluster_std=0.3)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
model = LinearSVC() 
model.fit(X_train, y_train) # 训练
y_pred = model.predict(X_test) 
accuracy_score(y_pred, y_test) # 评估
```



# 逻辑回归

逻辑回归是一种用于有监督学习的分类任务的简单算法，虽然算法的名字中含有“回归”二字，但其实它是用于分类问题的算法，逻辑回归通过计算数据属于各类别的概率来进行分类。

## 概述

逻辑回归是一种学习某个事件发生概率的算法，利用这个概率，可以对某个事件发生或者不发生进行二元分类。 虽然逻辑回归是二元分类的算法，但也可以用于三种类别以上的分类问题。


## 算法说明

逻辑回归根据数据$x$和表示其所属类别的标签$y$进行学习，计算概率。数据$x$可以当做由特征值组成的向量处理，如果标签是二元分类，则可以使用前面的$y=0, 1$，这种二元数值表示。

逻辑回归的基本思想与线性回归一致，对数据$x$乘以权重$w$，再加上偏置$w_0$，计算$w^Tx+w_0$的值，逻辑回归和线性回归在从数据中学习权重$w$和偏置$w_0$这一点上是相同的。

与线性回归不一样的地方在于，为了计算概率，逻辑回归的输出范围必须限制在0和1之间，逻辑回归使用Sigmoid函数$\sigma(z)=1/[1+exp(-z)]$，返回0和1之间的数值。

我们对输入数据$x$使用Sigmoid函数$\sigma(z)$，即使用$p=\sigma(w^Tx+w_0)$计算标签为$y$的概率$p$。二元分类通常将预测概率0.5作为阈值进行分类，当概率小于0.5时，将$y$的预测值分类为0，当概率大于0.5时，将$y$分类为1。当然根据问题的不同，有时会将阈值设置Wie大于或者小于0.5的值。

在学习过程中，我们使用逻辑损失作为误差函数进行最小化，与其他误差函数一样，逻辑损失是在分类失败时返回最大值，在分类成功时返回小值的函数，在与线性回归中引入的均方误差不同的是，我们无法通过式子变形来计算逻辑损失的最小值，因此需要采用梯度下降法通过数值计算来求解。

对于无法通过式子变形严密求解的情况，机器学习中经常会通过数值计算来近似求解。

### 示例代码

```python

```
# PCA算法

在众多降维算法中，PCA(Principal Component Analysis)主成分分析历史悠久，被广泛应用于各个领域。

使用PCA可以将相关的多变量数据以主成分简洁地表现出来。

## 概述

PCA是一种用于减少数据中的变量的算法，他对变量之间存在的相关性的数据很有效，是一种具有代表性的降维算法。降维是指在保留数据特征的前提下，以少量的变量表示有许多变量的数据，这有助于降低多变量数据分析的复杂度，比如在分析有100个变量的数据时，与其直接分析数据，不如使用5个变量表示数据，这样可以使后续分析比较容易。

减少数据变量的方法有两种：一种是只选择重要的变量，不适用其余变量；另一种是基于原来的变量构造新的变量。PCA使用的后一种方法。

也就是说，PCA可以使用低维数据变量表示高维空间中的数据，这个低纬的轴叫做主成分，以原来的变量的线性和的形式组成。

PCA可发现对象数据的方向和重要度，线的方向表示数据的方向，长度表示重要度。方向由构成新变量时对象数据变量的权重决定，而重要度与变量的偏差有关。在每个数据点取相同值的变量并不重要，但是在每个数据点取不同值的变量能很好地体现数据整体的特点。

以这两条线为新轴对原始数据进行变换后得打的图形，变换后的数据成为主成分得分，按照主成分轴的重要度的值从高到低排序，依次称他们为第一主成分，第二主成分。从转换后的图来看，第一主成分方向的方差大，第二主成分的方差不大，通过PCA计算得到第一主成分在方差最大的轴上，所以这个新的轴包含了更多的原始数据的特点。


## 算法说明

PCA采用以下步骤来寻找主成分。

1. 计算协方差矩阵。
2. 对协方差矩阵求解特征值问题，求出特征向量和特征值。
3. 以数据表示各个主成分方向。

TBD

## 示例代码

```python
from sklearn.decomposition import PCA
from sklearn.datasets import load_iris

data = load_iris()

n_components = 2

model = PCA(n_components=n_components)

model.fit(data.data)

print(model.transform(data.data))
```

## 详细说明

PCA可以将原始数据中的变量表示为新的轴的主成分，这些主成分按照贡献率大小排序，分别为第一主成分，第二主成分，这些通过计算累计贡献率，我们可以知道使用到第几个主成分为止可以包含原始数据多少比例的信息。


下图中横轴为主成分，纵轴为累计贡献率，其中A为变量之间存在相关性的数据的PCA结果，这时的累计贡献率分别为0.36、0.55、0.67、0.74、0.80，当根据累计恭贡献率选取主成分时，我们可以像“累计贡献率在0.7以上->4个主成分”“累计贡献率在0.8以上->5个主成分”这样，根据基准值决定主成分的数量。


而B是对变量之间没有相关性的数据进行PCA的结果，从图中可以看出，各个主成分的贡献率几乎相同，可是说这样的数据不适合用PCA进行降维，需要考虑其他方法。


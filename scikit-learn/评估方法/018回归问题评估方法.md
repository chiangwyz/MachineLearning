# 概述

回归问题的目标是预测大小关系有意义的值，所以有些评估方法和分类问题的评估方法不同。

## 使用Boston房价数据作为示例



```python
import pandas as pd
import numpy as np

data_url = "http://lib.stat.cmu.edu/datasets/boston"
raw_df = pd.read_csv(data_url, sep="\s+", skiprows=22, header=None)
data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])

# 只使用13个特征变量中的"住宅平均房间数(列名为RM)"
data = data[:, 5:6]
target = raw_df.values[1::2, 2]

np.set_printoptions(precision=5, suppress=True)


print("data", data[:2, :])
print("target", target)

from sklearn.linear_model import LinearRegression

model = LinearRegression()
model.fit(data, target)
y_pred = model.predict(data)

print("model.coef =", model.coef_)
print("model.intercept_ =", model.intercept_)

# model.coef = [9.10211]
# model.intercept_ = -34.670620776438554
```

下面使用matplotlib查看数据。

```python
import matplotlib.pyplot as plt

fig, ax = plt.subplots()
ax.scatter(data, target, color='pink', marker='s', label='data set')
ax.plot(data, y_pred, color='blue', label='LinearRegression')
ax.legend()
plt.show()
plt.savefig("boston house rent price prediction.pdf")
```

接下来使用均方误差和决定系数这两个指标来量化学习结果。

## 均方误差

对于要评估的数据，计算所有预测值与数据之间的误差的平方，并取平方的平均值，得到的就是均方误差(Mean-Square Error, MSE)，换言之，均方误差越小，预测效果越好。

```python
from sklearn.metrics import mean_squared_error
mean_sqaured = mean_squared_error(target, y_pred)

print("mean sqaure error =", mean_sqaured)
```

## 决定系数

决定系数(coefficient of determination)是使用均方误差来表示训练好的模型的预测效果的数值，也就是被称为$R^2$的系数。

当该系数取最大值1.0时，说明没有误差，它的值通常在0.0和1.0之间，但是如果预测的误差过大，也可能称为负值，换言之，该系数的值越接近1.0，说明模型对数据点的解释能力越强，我们可以使用r2_score函数计算决定系数。

r2_score是一种在统计学和机器学习中广泛使用的性能指标，用于评估回归模型的预测效果。它被称为决定系数（Coefficient of Determination），表示模型对数据的拟合程度。r2_score的值范围从负无穷大到1。一个模型的r2_score值越接近1，表示模型的预测越准确；如果一个模型的r2_score是0，则表示模型的预测不比总是预测目标变量平均值来得好；如果r2_score是负数，表示模型的预测效果还不如直接预测目标变量的平均值。

### 计算公式

$$
\begin{aligned}
R^2 = 1 - \frac{\sum_{i=1}^{n}(y_i-\hat{y_i})^2}{\sum_{i=1}^{n}(y_i-\overline{y})^2}
\end{aligned}
$$

其中：

* $y_i$是值；
* $\hat{y_i}$是预测值；
* $\overline{y}$是观测值的平均值；
* $n$是样本数量。

解释：

* 分子$\sum_{i=1}^{n}(y_i-\hat{y_i})^2$是模型预测误差的平方和，也称为残差平方和（RSS）。
* 分母$\sum_{i=1}^{n}(y_i-\overline{y})^2$是观测值与其平均值之差的平方和，也称为总平方和（TSS），它表示数据的总变异性。
* $R^2$表示模型预测的变异性占总变异性的比例。如果模型预测完全准确，则$R^2=1$；如果模型仅能预测出观测值的平均值，则$R^2=0$。

注意事项

* 当使用r2_score时，要注意它可能不适用于所有类型的数据或模型。例如，在数据非常不均匀分布的情况下，或者当模型的错误具有非常不同的方差时，r2_score可能不是一个好的性能度量。

* r2_score更适用于比较同一数据集上的不同模型，而不是跨数据集比较模型性能。

## 均方误差和决定系数指标的不同

前面解释了如何使用均方误差和决定系数两个指标评估回归问题，但是光看均方误差的数值不能判断精度是好还是坏，如果目标变量的方差较大，均方误差也会变大。而决定系数可以使用不依赖于目标变量方差的取值范围在0.0和1.0之间的值表示。

## 与其它算法进行比较


前面使用LinearRegression介绍了均方误差和决定系数，我们再来看一下使用其他算法的情况，下面使用SVR进行回归，并与使用LinearRegression时的情况进行比较。


## 防止过拟合的方法

### 将数据分为训练数据和验证数据

这种方法不适用实现给定的所有数据进行训练，而是留出一部分数据用于验证，不用于训练。可以将数据分为训练数据和验证数据，其中70%用于训练，30%用于验证，这个分割比例设为多少事没有明确规定的。如果数据量足够都，可以分割成6:4，如果数据量太少，也可以分割为8:2。

### 交叉验证

即使在数据分为训练数据和验证数据后进行评估，也依然可能发生过拟合。可以想到的原因是使用的训练数据和验证数据碰巧非常相似，反过来也有可能出现训练数据和验证数据非常不相似的情况。为了避免这种数据分割的误差，可以使用不同的分割方案进行多次验证，这就是所谓的交叉验证(cross validation)。






# 文本数据的转换处理

在自然语言处理领域，我们需要处理不能直接作为输入的文本数据。

我们介绍两种文本数据转换为表格数据的方法：一种是基于单词出现次数的转换；另一种是基于tf-idf的转换，我们将转换后的表格形式的数据应用机器学习模型，并比较他们的结果。

## 基于单词出现次数的转换


下面介绍基于单词出现次数的转换方法，这是一种通过统计文本中单词出现次数将文本数据转换为表格形式的数据的方法。

This is my car

This is my friend

This is my English book

表 文本数据中单词出现的次数

|| This | is | my | car | friend | English | book |
|--------|--------|--------|--------|--------|--------|--------|--------|
|文本1|1|1|1|1|0|0|0|
|文本2|1|1|1|0|1|0|0|
|文本3|1|1|1|0|0|1|1|


只考虑单词出现次数的做法无须考虑这些单词的重要度，对所有单词都平等地进行计数。


## 基于tf-idf的转换


tf-idf是一种基于tf(term frequency, 词频)和idf(inverse document frequency，逆文本频率指数)这两个指标来表示单词在文本中的重要度的方法。

tf是单词在文本中出现的频率，idf是一个包含该单词的文本越多，值就越小的值，换言之，想This这种出现在许多文本中的单词的idf就很小，就两个指标相乘得到的结果叫作tf-idf，下表是对刚才的文本数据计算的tf-idf的结果。

表 文本数据的tf-idf表示

|| This | is | my | car | friend | English | book |
|--------|--------|--------|--------|--------|--------|--------|--------|
|文本1|0.41|0.41|0.41|0.70|0|0|0|
|文本2|0.41|0.41|0.41|0|0.70|0|0|
|文本3|0.34|0.34|0.34|0|0|0.57|0.57|

This和my等单词在每个文本中都出现了，所以他们的tf-idf值较小，而car和friend等只在特定文本找那个出现的单词的tf-idf值则较大，行业术语和转悠名词等只有再特定文本中出现的词，往往具有寄到的tf-idf值，有时能够很好地表示包含这些单词的文本。


## 应用于机器学习模型

下面基于单词出现次数和tf-idf将文本数据转换为表格形式的数据。

## 补充知识


TF-IDF（Term Frequency-Inverse Document Frequency）是一种用于信息检索与文本挖掘的常用加权技术。它是一种统计方法，用以评估一个词语对于一个文件集或一个语料库中的其中一份文件的重要程度。词频 (TF) 表示词条在文档中出现的频率，而逆文档频率 (IDF) 表示词条在语料库中的分布情况。TF-IDF 值随着词条在文档中出现的次数成正比增加，但同时会随着词条在语料库中出现的频率成反比下降。

计算方法
1. 词频 (TF)
词频 (Term Frequency, TF) 表示词条（关键字）在文档中出现的频率。这个数字是对词条数目的归一化，以防止它偏向长的文件。（同一个词在长文档里可能会比短文档中出现次数更多）。其计算公式为：


$$
\begin{aligned}
TF(t,d)=\frac{num_t}{num_d}
\end{aligned}
$$

$num_t$: 词条t在文档d中出现的次数;

$num_d$: 文档d中词条总数;

2. 逆文档频率 (IDF)
逆文档频率 (Inverse Document Frequency, IDF) 是一个词条重要性的度量。某一特定词条的IDF，可以由总文档数目除以包含该词条之文档的数目，再将得到的商取对数得到：

$$
\begin{aligned}
IDF(t,d)=log\frac{|D|}{\{d\in D: t \in d\}}
\end{aligned}
$$

这里，
$|D|$ 是语料库中的文档总数。
IDF(t,d)=log\frac{|D|}{\{d\in D: t \in d\}}
$$表示包含词条 $t$ 的文档数目。如果词条不在数据中，会导致分母为零，因此一般情况下会在分母上加1，以进行平滑处理。
3. TF-IDF
然后，某一文档中的词条的TF-IDF值由TF和IDF乘积计算得出：

$$
\begin{aligned}
TFIDF(t,d,D)=TF(t,d)×IDF(t,D)
\end{aligned}
$$


这样，对于文档 d 中的每个词条，都可以计算出一个TF-IDF值。这个值越大，词条对文档的重要性越高。

4. 示例

假设我们有3个文档的集合，词条“example”在第一个文档中出现了3次，整个文档有100个词；在所有5个文档中，有2个文档包含词条“example”。那么，“example”的TF-IDF值为：

$$
TF=\frac{3}{100}=0.03\\ 
 \\
IDF=log\frac{5}{2}=log(2.5)\\
TFIDF=0.03*log(2.5)
$$



注意：

TF-IDF是一种用于评估词语在文档中相对重要性的权重计算方法。它基于这样的假设：如果一个词在某个文档中频繁出现，但在其他文档中不那么常见，则认为该词对理解该文档的内容很重要。如果你在其他书籍或资料中看到了看似相反的解释，可能需要结合上下文和具体的计算方法来综合理解。